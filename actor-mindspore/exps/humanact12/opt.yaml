activation: gelu
archiname: transformer
batch_size: 20
dataset: humanact12
debug: false
expname: exps
folder: exps/humanact12
glob: true
glob_rot:
- 3.141592653589793
- 0
- 0
jointstype: vertices
lambda_kl: 1.0e-05
lambda_rc: 1.0
lambda_rcxyz: 1.0
lambdas:
  kl: 1.0e-05
  rc: 1.0
  rcxyz: 1.0
latent_dim: 256
losses:
- rc
- rcxyz
- kl
lr: 0.0001
max_len: -1
min_len: -1
modelname: cvae_transformer_rc_rcxyz_kl
modeltype: cvae
num_epochs: 1400
num_frames: 60
num_layers: 8
num_seq_max: -1
pose_rep: rot6d
sampling: conseq
sampling_step: 1
snapshot: 10
translation: true
vertstrans: false
